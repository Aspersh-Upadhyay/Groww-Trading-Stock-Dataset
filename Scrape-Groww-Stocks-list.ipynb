{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "yJ_wcZbRXWUH"
      },
      "outputs": [],
      "source": [
        "# importing required libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "pNrfmsAAXcwO"
      },
      "outputs": [],
      "source": [
        "# creating soup \n",
        "def extract(page):\n",
        "  url = f'https://groww.in/stocks/filter?closePriceHigh=100000&closePriceLow=0&marketCapHigh=2000000&marketCapLow=0&page={page}&size=15&sortType=ASC'\n",
        "  r = requests.get(url)\n",
        "  soup = BeautifulSoup(r.content, 'html.parser')\n",
        "  return soup  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "pr137vC-YJn6"
      },
      "outputs": [],
      "source": [
        "# this function will only extract header of the data it will only return the columns name\n",
        "def header(soup):\n",
        "  col_name  = [title.text for title in soup.find_all('th')]\n",
        "  return col_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "n0Yevp1ua9n_"
      },
      "outputs": [],
      "source": [
        "# first we are extracting here table header\n",
        "soup = extract(0)\n",
        "col_name = header(soup)\n",
        "\n",
        "# then use col_name to create dataFrame column name\n",
        "stock_data = pd.DataFrame(columns = col_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "IVA3HSEB4dkz"
      },
      "outputs": [],
      "source": [
        "# here we are shaping our data and adding data in stock_data DataFrame\n",
        "def transform(soup):\n",
        "  for j in soup.find_all('tr')[1:]: # find table row \n",
        "    row_data = j.find_all('td') # find table data \n",
        "    row = [i.text for i in row_data] # get the text  \n",
        "    length = len(stock_data) # checking length of our stock_data\n",
        "    stock_data.loc[length] = row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSeT9fYbC4cn",
        "outputId": "43146f45-9cb6-4bb9-92ca-ea7555616c64"
      },
      "outputs": [],
      "source": [
        "# here we are looping our function to extract all the pages\n",
        "for i in range(0,272):\n",
        "  print(f\"extracting page no.{i}\")\n",
        "  soup = extract(i)\n",
        "  transform(soup)\n",
        "\n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "oqU_GyTaav_r"
      },
      "outputs": [],
      "source": [
        "# here we are changing data into csv format\n",
        "stock_data.to_csv(\"Groww-Stocks-list.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIBpLJt9qmAN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
